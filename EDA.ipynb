{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHdmmBKSfU7m"
      },
      "source": [
        "# Data Engineer Assessment\n",
        "## UC01: TTD_DE_UC01_EDA: Perform `Exploratory Data Analysis (EDA)` on provided CSV data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5CzyDpRgtJG"
      },
      "source": [
        "## Summary\n",
        "This assessments evaluate the capabilities of the candidate in solving data engineering use cases. The candidate is required to solve the below assessment questions using a Jupyter notebook and post the solutions in the notebook in the assessment section.  \n",
        "\n",
        "Each assessment is structured as a collection of one or more scenarios that need to be addressed by the data engineer.\n",
        "\n",
        "\n",
        "* __Problem Statement__ - Business users have asked the data engineers to assist with exploratory data analysis to enable business make informed decisions.\n",
        "* __Description__ - Business would like to perform `Exploratory Data Analysis` on the dataset as part of reporting and also to prepare data for Machine Learning purposes.  \n",
        "The business user has recently joined the organization and is unfamiliar with the data and has asked the data engineer to just assist with the review of the data so that they generate reports together.\n",
        "\n",
        "The business user would first like to explore the data and see if there are any patterns in the data that can be used for reporting.\n",
        "\n",
        "\n",
        "## Code Complexity\n",
        "- Low / Medium\n",
        "\n",
        "\n",
        "## `Diagram - Also refer PDF in folder`\n",
        "\n",
        "![Exploratory Data Analysis](./TTD_UC01_EDA.png \"Exploratory Data\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvLjeRgChxtp"
      },
      "source": [
        "## Datasets:\n",
        "\n",
        "`File Location`: Refer to the attached `data` folder for information. \n",
        "The `data` folder is at the following location. - [data.zip]( \n",
        "https://drive.google.com/file/d/1NBXP1nFhyuZGgO8YHLL6yQqAPuM1zNca/view?usp=sharing)\n",
        "\n",
        "* Vehicles (vehicles.csv)  at the plants (plants.csv) are built to order (orders.csv) placed - order_number\n",
        "* Vehicles are manufactured at different Company plants (plants.csv)-  (plant_code_id)\n",
        "* Customer (customers.csv) provides reviews(welcome_call.csv) 60 to 80 days after the vehicles are delivered(vin)\n",
        "* Orders (orders.csv) are logged by sales_rep_number at various BMW dealerships.\n",
        "* Sales (sales_rep.csv) representatives are linked to dealership (dealers.csv) and have dealership names\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuTGDk3Rh2Bx"
      },
      "source": [
        "## Perform the following joins:\n",
        "\n",
        "* Link all the data based on the statements made above to create a larger dataset that answers the below questions.\n",
        "* Identify any duplicates in the data and perform cleanup of the duplicates. Just drop the duplicates columns.\n",
        "* The Dataset must contain vehicles linked to the order, sentiments, sales people, plants\n",
        "* Provide the name of the sales person (first_name, last_name and sales_number the dealership)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fJaKs5qiOD1"
      },
      "source": [
        "## Questions: `Exploratory Data Analysis - Provide graphs for options below and document your observations in markdown. `\n",
        "\n",
        "1. Perform `Exploratory data analysis` and provide insights into the data.\n",
        "2.  Provide the distribution by brand, model, iso_country.\n",
        "3. Provide the percentage of customers that have purchased more than 1 car.\n",
        "4.  Provide the distribution of the vehicles manufactured by the plants and provide information brand, model  etc.\n",
        "5.  Provide the top sales peoples per dealership - 10 top sales people\n",
        "6.  Indicate the total sales per dealership.\n",
        "7.  Get the models of the cars that had the most positive reviews (reviews greater than 3.5)\n",
        "8.  Provide a distribution of the vehicles by different status.\n",
        "9.  List all the dealerships that have sold the Rolls-Royce brand.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg31xO4Tie_t"
      },
      "source": [
        "## Libraries or Options used\n",
        "* Jupyter Notebook - Install and run locally on your laptop or device.\n",
        "* PySpark, Pandas and matplot lib or similar plotting libraries.\n",
        "* Other Python libraries required for Exploratory Data Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHg-Bj6rinNj"
      },
      "source": [
        "## `Acceptance Criteria`\n",
        "The following acceptance criteria must be met:\n",
        "\n",
        "1. Perform Exploratory data Analysis and present your results as observations.\n",
        "2. Python Graph libraries must be used to plot graphs to support your findings.\n",
        "3. Comment your notebook file with markdown indicating observations: and write statements to indicate your observations.\n",
        "4. Perform Analysis fo the Data using Spark or Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caDAkcnGisWu"
      },
      "source": [
        "# Implementation\n",
        "\n",
        "Provide all the implementation steps in the sections that follow. Ensure that you provide detailed explanations of the approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v2Rt81WjBE-"
      },
      "source": [
        "### Import the libraries that you need for EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_mfc2MJi_do"
      },
      "outputs": [],
      "source": [
        "# Import any relevant libraries\n",
        "import os\n",
        "import re\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when as when\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# initialize SparkSession object\n",
        "spark = SparkSession.builder.appName(\"de_assessment_eda\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3tZe7SHlNlF"
      },
      "source": [
        "#### List of expected dataframes to be loaded\n",
        "\n",
        "\n",
        "  * Vehicles (vehicles.csv) at the plants (plants.csv) are built to order (orders.csv) placed - order_number\n",
        "  * Vehicles are manufactured at different Company plants (plants.csv)- (plant_code_id)\n",
        "  * Customer (customers.csv) provides reviews(welcome_call.csv) 60 to 80 days after the vehicles are delivered(vin)\n",
        "  * Orders (orders.csv) are logged by sales_rep_number at various BMW dealerships.\n",
        "  * Sales (sales_rep.csv) representatives are linked to dealership (dealers.csv) and have dealership names\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTC5CpH_jWSN"
      },
      "source": [
        "### Load the data from the data folder into the data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8Cw2-CmfTn2"
      },
      "outputs": [],
      "source": [
        "# Write your code below to load the relevant data into a data frame\n",
        "# Perform any Clean up operations if required. remove duplicates etc.\n",
        "\n",
        "\n",
        "## Customers Spark DataFrame converted to a TempView in order to enable SparkSQL\n",
        "\n",
        "spark_customers_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/customers.csv\").dropDuplicates().dropna(how='all')\n",
        "\n",
        "spark_customers_df.createOrReplaceTempView(\"customerTempView\")\n",
        "spark_customers_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM customerTempView WHERE left(customer_id,3) like 'CNI%'\") #filtering invalid CustomerID values\n",
        "\n",
        "## Vehicle Orders Spark DataFrame\n",
        "spark_orders_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/orders.csv\")\n",
        "\n",
        "## Dealership Spark DataFrame converted to a TempView in order to enable SparkSQL\n",
        "spark_dealers_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/dealers.csv\").dropDuplicates()\n",
        "spark_dealers_df.createOrReplaceTempView(\"dealershipTempView\")\n",
        "spark_dealers_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM dealershipTempView WHERE left(dealer_code,3) like 'DNI%'\") #filtering invalid DealershipNumber values\n",
        "\n",
        "## BMW Plant Spark DataFrame\n",
        "spark_plants_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/plants.csv\")\n",
        "\n",
        "\n",
        "## SalesRep Spark DataFrame converted to a TempView in order to enable SparkSQL\n",
        "spark_sales_person_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/sales_person.csv\").dropDuplicates()\n",
        "spark_sales_person_df.createOrReplaceTempView(\"salesTempView\")\n",
        "spark_sales_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM salesTempView WHERE left(sales_number,3) like 'SNI%'\") #filtering invalid SalesNumber values\n",
        "\n",
        "## Vehicle Make Spark DataFrame\n",
        "spark_vehicle_make_df  = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/vehicle_make.csv\").dropDuplicates()\n",
        "\n",
        "## Vehicle Spark DataFrame with a slight valiue correction on some bad data on \"fuel_type\"\n",
        "spark_vehicles_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/vehicles.csv\")\n",
        "spark_vehicles_df = spark_vehicles_df.withColumn(\"fuel_type\", when(spark_vehicles_df[\"fuel_type\"] == \"hyrdogen\", \"hydrogen\").otherwise(spark_vehicles_df[\"fuel_type\"])) #corrected fuel_type value that is bad data .i.e \"hyrdogen\" and not \"hydrogen\" \n",
        "\n",
        "## Welcome call Spark DataFrame\n",
        "spark_welcome_call_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/welcome_call.csv\")\n",
        "\n",
        "## Welcome Call (Deltas) Spark DataFrame\n",
        "spark_welcome_call_deltas_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/welcome_call_deltas.csv\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHeEOIeLkDfA"
      },
      "source": [
        "#### Question: Did you need to perform any clean up on the dataframes. If yes. What cleanup operations did you perform\n",
        "\n",
        "#### *Answer*: \n",
        "\n",
        "\n",
        "# 1  Removing rows with the invalid customer ID values \n",
        ">> spark_customers_df.createOrReplaceTempView(\"customerTempView\")\n",
        ">> spark_customers_df = spark.sql(sqlQuery=\"SELECT * FROM customerTempView WHERE left(customer_id,3) like 'CNI%'\")\n",
        "\n",
        "\n",
        "# 2 Removing rows with the invalid Dealer Code values\n",
        ">> spark_dealers_df.createOrReplaceTempView(\"dealershipTempView\")\n",
        ">> spark_dealers_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM dealershipTempView WHERE left(dealer_code,3) like 'DNI%'\") #filtering invalid DealershipNumber values\n",
        "\n",
        "# 3 Removing rows with the invalid SalesID values\n",
        ">> spark_sales_person_df.createOrReplaceTempView(\"salesTempView\")\n",
        ">> spark_sales_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM salesTempView WHERE left(sales_number,3) like 'SNI%'\") #filtering invalid SalesNumber values\n",
        "\n",
        "# 4 Making sure that the fuel_type column values are void of typos\n",
        ">> spark_vehicles_df = spark_vehicles_df.withColumn(\"fuel_type\", when(spark_vehicles_df[\"fuel_type\"] == \"hyrdogen\", \"hydrogen\").otherwise(spark_vehicles_df[\"fuel_type\"]))\n",
        "\n",
        "# 5 Dropped Duplicates on 4 Datasets, namely:\n",
        " \n",
        ">> \"dealership\"\n",
        "   - Overall Count:\t2598  \n",
        "   - Without Duplicates:\t2590\n",
        ">> sales_person\"\n",
        "   - Overall Count:\t30827 \n",
        "   - Without Duplicates:\t30602\n",
        ">> vehicle_make\"\n",
        "   - Overall Count:\t481 \n",
        "   - Without Duplicates:\t448\n",
        ">> customer\"\n",
        "   - Overall Count:\t288251 \n",
        "   - Without Duplicates:\t280989\n",
        "\n",
        "# 6 Dropped Rows that were bad (specifically only having missing fields) for the customers Dataframe\n",
        "\n",
        "   Overall Count:\t288251 \n",
        "   DropNa('Any') function:\t15544\n",
        "   DropNa('All') function:\t288251\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU_MuP2KkeRP"
      },
      "source": [
        "### Provide some statistical information about the data you just loaded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4xFBsWpko8O"
      },
      "outputs": [],
      "source": [
        "# Write code to provide statistical information about each dataframe that you just loaded.\n",
        "\n",
        "# Using the Pandas.describe() function\n",
        "spark_customers_df_filtered.toPandas().describe()\n",
        "spark_welcome_call_df.toPandas().describe()\n",
        "spark_vehicles_df.toPandas().describe()\n",
        "spark_vehicle_make_df.toPandas().describe()\n",
        "spark_sales_df_filtered.toPandas().describe()\n",
        "spark_dealers_df_filtered.toPandas().describe()\n",
        "spark_orders_df.toPandas().describe()\n",
        "spark_plants_df.toPandas().describe()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5WHnAOSjrsu"
      },
      "source": [
        "### Perform all the relevant join operations between the datasets.\n",
        "\n",
        "Hint! - Relationship between the datasets is mentioned above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C9ukPTuj4TV"
      },
      "outputs": [],
      "source": [
        "# Perform the queries to perform the relevant dataframe join operations.\n",
        "vehicles_list = [\"order_number\",\"vin\",\"fuel_type\",\"transmission_type\",\"prod_plant_id\",\"production_country\",\"dealer_number\",\"export_country\",\"steering_wheel_position\",\"cabin_door_count\",\"engine_series\",\"drive_type\",\"price\",\"currency\"]\n",
        "\n",
        "#Joining plant table to orders table\n",
        "\n",
        "vehicle_plant_df = spark_vehicles_df[vehicles_list].join(spark_plants_df[\"plant_id\",\"plant_name\",\"country\",\"iso_country_code\"],spark_vehicles_df['prod_plant_id'] == spark_plants_df['plant_id'],\"leftouter\" ).drop('prod_plant_id','brand','production_country')\n",
        "\n",
        "#  #Joining vehicle table to orders table\n",
        "vehicle_plant_order_df = spark_vehicles_df.join(spark_orders_df,vehicle_plant_df['order_number']==spark_orders_df['order_number'],\"inner\" ).drop('iso_country_code','order_number')\n",
        "\n",
        "#  #Joining orders table to welcome_call table\n",
        "vehicle_order_reviews = spark_welcome_call_df[\"review_id\",\"vin\",\"order_number\",\"review\",\"ratings\"].join(spark_orders_df,spark_welcome_call_df['order_number']==spark_orders_df['order_number'],\"left\").drop('order_number')\n",
        "# vehicle_order_reviews.sort('ratings').show()\n",
        "\n",
        "vehicle_order_reviews.createOrReplaceTempView(\"dealer_sentiment\")\n",
        "sentiment_per_dealership = spark.sql(sqlQuery=\"SELECT avg(ratings) over (partition by dealer_number order by review_id) average_rating_dealer, dealer_number  FROM dealer_sentiment group by dealer_number, ratings ,review_id\")\n",
        "\n",
        "# #Joining SalesRep Dataframe to Orders Dataframe based on the sales_rep reference ID\n",
        "order_sales_rep = spark_orders_df.join(spark_sales_df_filtered['sales_number',\"dealer_number\",\"sex\",\"employment_type\"],spark_sales_df_filtered['sales_number']==spark_orders_df['sales_rep_number'],\"left\").drop('sales_number','dealer_number').drop('iso_country_code')\n",
        "\n",
        "# ##Joining SalesRep data to dealership data\n",
        "sales_rep_dealership = spark_sales_df_filtered[\"sales_number\",\"first_name\",\"last_name\",\"personnel_number\",\"employment_type\",\"department_code\",\"dealer_number\",\"sex\",\"date_of_birth\",\"customer_address\"].join(spark_dealers_df_filtered[\"dealer_code\",\"dealer_company\",\"dealer_address\"],spark_sales_df_filtered['dealer_number']==spark_dealers_df_filtered['dealer_code'],\"inner\").drop('dealer_code')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XXOXAl0kX7y"
      },
      "source": [
        "#### Question: Did you perform any joins on the datasets. If yes, what joins. Also what information was available after the joins were performed.\n",
        "\n",
        "#### *Answer*: \n",
        "\n",
        "# Joined Vehicle Dataframe with Plant Dataframe in order to map the Production Plant ID to a country and also to understand a plant's vehicle production patterns\n",
        "\n",
        "# Joined Vehicle Dataframe with Orders Dataframe in order to get a Vehicle's Order status, CustomerID in order\n",
        "\n",
        "# Joined Welcome Call Dataframe with Dealership Dataframe in order to get more info on customer sentiment at dealerships \n",
        "\n",
        "# The JOINS that were used were all LEFT JOINS, with the bigger table on the left side of the JOINS (in case Spark's Cost Based Optimization does not kick in as it should)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aDRWfnJl_fZ"
      },
      "source": [
        "### Perform All the standard Exploratory Data Analysis in the sections that follow to provide information to the Business users about the data. Report your findings in the form of Graphs or Response statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E-tNWhomPXn"
      },
      "outputs": [],
      "source": [
        "# Example: Write down the distribution of Vehicles by plant and iso_country and plot a bar graph\n",
        "\n",
        "vehicle_plant_df.createOrReplaceTempView(\"vehicle_by_plant_dist\")\n",
        "vehicle_by_plant_dist = spark.sql(\"SELECT plant_id, iso_country_code, count(vin) cars_sold FROM vehicle_by_plant_dist group by 1,2 order by 1,2\") #VIN distrbution by plant_id and iso_country_code\n",
        "\n",
        "pandas_vehicle_by_plant_dist = vehicle_by_plant_dist.toPandas()\n",
        "\n",
        "pivot_df = pandas_vehicle_by_plant_dist.pivot( columns=[\"iso_country_code\",\"plant_id\"], values=\"cars_sold\").fillna(0)\n",
        "\n",
        "# Plotting the g bar chart\n",
        "pivot_df.plot(kind='bar', figsize=(12, 8), width=0.8)\n",
        "\n",
        "# # Set labels and title\n",
        "plt.xlabel(\"ID\")\n",
        "plt.ylabel(\"Units\")\n",
        "plt.title(\"Vehicles Sold by plant and country\")\n",
        "# Show the plot\n",
        "plt.xticks(rotation=0)  # Keep x-axis labels horizontal\n",
        "plt.legend(title='Vehicles Sold', bbox_to_anchor=(1.05, 1), loc='upper left')  # Position the legend outside the plot\n",
        "plt.tight_layout()  # Adjust the plot to ensure everything fits\n",
        "plt.show()\n",
        "\n",
        "vehicle_order_reviews.createOrReplaceTempView(\"dealer_sentiment\")\n",
        "sentiment_per_dealership = spark.sql(sqlQuery=\"SELECT avg(ratings) over (partition by dealer_number order by review_id) average_rating_dealer, dealer_number, ratings, review_id  FROM dealer_sentiment group by dealer_number, ratings ,review_id\")\n",
        "\n",
        "\n",
        "sentiment_per_dealership_pandas = sentiment_per_dealership.toPandas()\n",
        "\n",
        "pivot_df = sentiment_per_dealership_pandas.pivot(index=\"review_id\" ,columns=[\"dealer_number\"], values=\"ratings\").fillna(0)\n",
        "\n",
        "# Plotting the g bar chart\n",
        "pivot_df.plot(kind='bar', figsize=(12, 8), width=0.8)\n",
        "\n",
        "# # Set labels and title\n",
        "plt.xlabel(\"ID\")\n",
        "plt.ylabel(\"Units\")\n",
        "plt.title(\"Vehicles Sold by plant and country\")\n",
        "# Show the plot\n",
        "plt.xticks(rotation=0)  # Keep x-axis labels horizontal\n",
        "plt.legend(title='Vehicles Sold', bbox_to_anchor=(1.05, 1), loc='upper left')  # Position the legend outside the plot\n",
        "plt.tight_layout()  # Adjust the plot to ensure everything fits\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdFMhJHUmZXf"
      },
      "outputs": [],
      "source": [
        "# Write your own exploratory data analysis on the ingested dataframe and report on the different findings.\n",
        "# also provide visual aids for each finding.\n",
        "\n",
        "\n",
        "#  fixing matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Lb84b631w_H"
      },
      "outputs": [],
      "source": [
        "# Use the matplotlib libraries or other graphing libraries and create charts to support your findings\n",
        "import matplotlib\n",
        "\n",
        "#  fixing matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhk3rwcsmt3H"
      },
      "source": [
        "### Report all your Findings:\n",
        "\n",
        "Report your findings in bullet points.\n",
        "Example: For illustration purpose only - replace below with your own findings and support with Evidence\n",
        "1. The US plant manufactured the most number of vehicles in 2023 etc. There were 30,000 vehicles manufactured at the plant etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb1_0AKGmlO0"
      },
      "source": [
        "## `Acceptance Criteria`\n",
        "The following acceptance criteria must be met:\n",
        "\n",
        "1. Perform Exploratory data Analysis and present your results as observations.\n",
        "2. Python Graph libraries must be used to plot graphs to support your findings.\n",
        "3. Comment your notebook file with markdown indicating observations: and write statements to indicate your observations.\n",
        "4. Perform Analysis fo the Data using Spark or Pandas"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
