{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHdmmBKSfU7m"
      },
      "source": [
        "# Data Engineer Assessment\n",
        "## UC01: TTD_DE_UC01_EDA: Perform `Exploratory Data Analysis (EDA)` on provided CSV data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5CzyDpRgtJG"
      },
      "source": [
        "## Summary\n",
        "This assessments evaluate the capabilities of the candidate in solving data engineering use cases. The candidate is required to solve the below assessment questions using a Jupyter notebook and post the solutions in the notebook in the assessment section.  \n",
        "\n",
        "Each assessment is structured as a collection of one or more scenarios that need to be addressed by the data engineer.\n",
        "\n",
        "\n",
        "* __Problem Statement__ - Business users have asked the data engineers to assist with exploratory data analysis to enable business make informed decisions.\n",
        "* __Description__ - Business would like to perform `Exploratory Data Analysis` on the dataset as part of reporting and also to prepare data for Machine Learning purposes.  \n",
        "The business user has recently joined the organization and is unfamiliar with the data and has asked the data engineer to just assist with the review of the data so that they generate reports together.\n",
        "\n",
        "The business user would first like to explore the data and see if there are any patterns in the data that can be used for reporting.\n",
        "\n",
        "\n",
        "## Code Complexity\n",
        "- Low / Medium\n",
        "\n",
        "\n",
        "## `Diagram - Also refer PDF in folder`\n",
        "\n",
        "![Exploratory Data Analysis](./TTD_UC01_EDA.png \"Exploratory Data\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvLjeRgChxtp"
      },
      "source": [
        "## Datasets:\n",
        "\n",
        "`File Location`: Refer to the attached `data` folder for information. \n",
        "The `data` folder is at the following location. - [data.zip]( \n",
        "https://drive.google.com/file/d/1NBXP1nFhyuZGgO8YHLL6yQqAPuM1zNca/view?usp=sharing)\n",
        "\n",
        "* Vehicles (vehicles.csv)  at the plants (plants.csv) are built to order (orders.csv) placed - order_number\n",
        "* Vehicles are manufactured at different Company plants (plants.csv)-  (plant_code_id)\n",
        "* Customer (customers.csv) provides reviews(welcome_call.csv) 60 to 80 days after the vehicles are delivered(vin)\n",
        "* Orders (orders.csv) are logged by sales_rep_number at various BMW dealerships.\n",
        "* Sales (sales_rep.csv) representatives are linked to dealership (dealers.csv) and have dealership names\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuTGDk3Rh2Bx"
      },
      "source": [
        "## Perform the following joins:\n",
        "\n",
        "* Link all the data based on the statements made above to create a larger dataset that answers the below questions.\n",
        "* Identify any duplicates in the data and perform cleanup of the duplicates. Just drop the duplicates columns.\n",
        "* The Dataset must contain vehicles linked to the order, sentiments, sales people, plants\n",
        "* Provide the name of the sales person (first_name, last_name and sales_number the dealership)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fJaKs5qiOD1"
      },
      "source": [
        "## Questions: `Exploratory Data Analysis - Provide graphs for options below and document your observations in markdown. `\n",
        "\n",
        "1. Perform `Exploratory data analysis` and provide insights into the data.\n",
        "2.  Provide the distribution by brand, model, iso_country.\n",
        "3. Provide the percentage of customers that have purchased more than 1 car.\n",
        "4.  Provide the distribution of the vehicles manufactured by the plants and provide information brand, model  etc.\n",
        "5.  Provide the top sales peoples per dealership - 10 top sales people\n",
        "6.  Indicate the total sales per dealership.\n",
        "7.  Get the models of the cars that had the most positive reviews (reviews greater than 3.5)\n",
        "8.  Provide a distribution of the vehicles by different status.\n",
        "9.  List all the dealerships that have sold the Rolls-Royce brand.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg31xO4Tie_t"
      },
      "source": [
        "## Libraries or Options used\n",
        "* Jupyter Notebook - Install and run locally on your laptop or device.\n",
        "* PySpark, Pandas and matplot lib or similar plotting libraries.\n",
        "* Other Python libraries required for Exploratory Data Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHg-Bj6rinNj"
      },
      "source": [
        "## `Acceptance Criteria`\n",
        "The following acceptance criteria must be met:\n",
        "\n",
        "1. Perform Exploratory data Analysis and present your results as observations.\n",
        "2. Python Graph libraries must be used to plot graphs to support your findings.\n",
        "3. Comment your notebook file with markdown indicating observations: and write statements to indicate your observations.\n",
        "4. Perform Analysis fo the Data using Spark or Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caDAkcnGisWu"
      },
      "source": [
        "# Implementation\n",
        "\n",
        "Provide all the implementation steps in the sections that follow. Ensure that you provide detailed explanations of the approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v2Rt81WjBE-"
      },
      "source": [
        "### Import the libraries that you need for EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0_mfc2MJi_do"
      },
      "outputs": [],
      "source": [
        "# Import any relevant libraries\n",
        "import os\n",
        "import re\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when as when\n",
        "import pandas as pd\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# initialize SparkSession object\n",
        "spark = SparkSession.builder.appName(\"de_assessment_eda\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3tZe7SHlNlF"
      },
      "source": [
        "#### List of expected dataframes to be loaded\n",
        "\n",
        "\n",
        "  * Vehicles (vehicles.csv) at the plants (plants.csv) are built to order (orders.csv) placed - order_number\n",
        "  * Vehicles are manufactured at different Company plants (plants.csv)- (plant_code_id)\n",
        "  * Customer (customers.csv) provides reviews(welcome_call.csv) 60 to 80 days after the vehicles are delivered(vin)\n",
        "  * Orders (orders.csv) are logged by sales_rep_number at various BMW dealerships.\n",
        "  * Sales (sales_rep.csv) representatives are linked to dealership (dealers.csv) and have dealership names\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTC5CpH_jWSN"
      },
      "source": [
        "### Load the data from the data folder into the data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8Cw2-CmfTn2"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Spark DataFrame for Customer Data converted to a TempView in order to enable SparkSQL and we are also filtering out invalid customer IDs\n",
        "spark_customers_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/customers.csv\").dropDuplicates().dropna(how='all')\n",
        "spark_customers_df.createOrReplaceTempView(\"customerTempView\")\n",
        "spark_customers_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM customerTempView WHERE left(customer_id,3) like 'CNI%'\") #filtering invalid CustomerID values\n",
        "\n",
        "\n",
        "## Spark DataFrame for the Orders Dataset \n",
        "spark_orders_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/orders.csv\")\n",
        "\n",
        "## Spark DataFrame for Dealership information converted to a TempView in order to enable SparkSQL\n",
        "spark_dealers_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/dealers.csv\").dropDuplicates()\n",
        "spark_dealers_df.createOrReplaceTempView(\"dealershipTempView\")\n",
        "spark_dealers_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM dealershipTempView WHERE left(dealer_code,3) like 'DNI%'\") #filtering invalid DealershipNumber values\n",
        "\n",
        "## Spark DataFrame for the Plant dataset\n",
        "spark_plants_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/plants.csv\")\n",
        "\n",
        "\n",
        "## Sales Representative Information Spark DataFrame converted to a TempView in order to enable SparkSQL\n",
        "spark_sales_person_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/sales_person.csv\").dropDuplicates()\n",
        "spark_sales_person_df.createOrReplaceTempView(\"salesTempView\")\n",
        "spark_sales_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM salesTempView WHERE left(sales_number,3) like 'SNI%'\") #filtering invalid SalesNumber values\n",
        "\n",
        "## Vehicle Make Spark DataFrame\n",
        "spark_vehicle_make_df  = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/vehicle_make.csv\").dropDuplicates()\n",
        "\n",
        "# ## Vehicle Spark DataFrame with a slight valiue correction on some bad data on \"fuel_type\"\n",
        "spark_vehicles_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/vehicles.csv\")\n",
        "spark_vehicles_df = spark_vehicles_df.withColumn(\"fuel_type\", when(spark_vehicles_df[\"fuel_type\"] == \"hyrdogen\", \"hydrogen\").otherwise(spark_vehicles_df[\"fuel_type\"])) #corrected fuel_type value that is bad data .i.e \"hyrdogen\" and not \"hydrogen\" \n",
        "\n",
        "\n",
        "## Spark DataFrame on the Welcome Call information\n",
        "spark_welcome_call_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/welcome_call.csv\")\n",
        "\n",
        "## Welcome Call (Deltas) Spark DataFrame\n",
        "spark_welcome_call_deltas_df = spark.read.option(\"delimiter\",'|').option(\"header\",\"true\").csv(\"data/welcome_call_deltas.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHeEOIeLkDfA"
      },
      "source": [
        "#### Question: Did you need to perform any clean up on the dataframes. If yes. What cleanup operations did you perform\n",
        "\n",
        "#### *Answer*: \n",
        "\n",
        "\n",
        "# 1  Removing rows with the invalid customer ID values \n",
        ">> spark_customers_df.createOrReplaceTempView(\"customerTempView\")\n",
        ">> spark_customers_df = spark.sql(sqlQuery=\"SELECT * FROM customerTempView WHERE left(customer_id,3) like 'CNI%'\")\n",
        "\n",
        "\n",
        "# 2 Removing rows with the invalid Dealer Code values\n",
        ">> spark_dealers_df.createOrReplaceTempView(\"dealershipTempView\")\n",
        ">> spark_dealers_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM dealershipTempView WHERE left(dealer_code,3) like 'DNI%'\") #filtering invalid DealershipNumber values\n",
        "\n",
        "# 3 Removing rows with the invalid SalesID values\n",
        ">> spark_sales_person_df.createOrReplaceTempView(\"salesTempView\")\n",
        ">> spark_sales_df_filtered = spark.sql(sqlQuery=\"SELECT * FROM salesTempView WHERE left(sales_number,3) like 'SNI%'\") #filtering invalid SalesNumber values\n",
        "\n",
        "# 4 Making sure that the fuel_type column values are void of typos\n",
        ">> spark_vehicles_df = spark_vehicles_df.withColumn(\"fuel_type\", when(spark_vehicles_df[\"fuel_type\"] == \"hyrdogen\", \"hydrogen\").otherwise(spark_vehicles_df[\"fuel_type\"]))\n",
        "\n",
        "# 5 Dropped Duplicates on 4 Datasets, namely:\n",
        " \n",
        ">> \"dealership\"\n",
        "   - Overall Count:\t2598  \n",
        "   - Without Duplicates:\t2590\n",
        ">> sales_person\"\n",
        "   - Overall Count:\t30827 \n",
        "   - Without Duplicates:\t30602\n",
        ">> vehicle_make\"\n",
        "   - Overall Count:\t481 \n",
        "   - Without Duplicates:\t448\n",
        ">> customer\"\n",
        "   - Overall Count:\t288251 \n",
        "   - Without Duplicates:\t280989\n",
        "\n",
        "# 6 Dropped Rows that were bad (specifically only having missing fields) for the customers Dataframe\n",
        "\n",
        "   Overall Count:\t288251 \n",
        "   DropNa('Any') function:\t15544\n",
        "   DropNa('All') function:\t288251\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU_MuP2KkeRP"
      },
      "source": [
        "### Provide some statistical information about the data you just loaded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4xFBsWpko8O"
      },
      "outputs": [],
      "source": [
        "# Write code to provide statistical information about each dataframe that you just loaded.\n",
        "\n",
        "# Using the Pandas.describe() function\n",
        "spark_customers_df_filtered.toPandas().describe()\n",
        "spark_welcome_call_df.toPandas().describe()\n",
        "spark_vehicles_df.toPandas().describe()\n",
        "spark_vehicle_make_df.toPandas().describe()\n",
        "spark_sales_df_filtered.toPandas().describe()\n",
        "spark_dealers_df_filtered.toPandas().describe()\n",
        "spark_orders_df.toPandas().describe()\n",
        "spark_plants_df.toPandas().describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5WHnAOSjrsu"
      },
      "source": [
        "### Perform all the relevant join operations between the datasets.\n",
        "\n",
        "Hint! - Relationship between the datasets is mentioned above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C9ukPTuj4TV"
      },
      "outputs": [],
      "source": [
        "# # Perform the queries to perform the relevant dataframe join operations.\n",
        "vehicles_list = [\"order_number\",\"vin\",\"fuel_type\",\"transmission_type\",\"prod_plant_id\",\"production_country\",\"dealer_number\",\"export_country\",\"steering_wheel_position\",\"cabin_door_count\",\"engine_series\",\"drive_type\",\"price\",\"currency\"]\n",
        "\n",
        "# #Joining plant table to orders table\n",
        "vehicle_plant_df = spark_vehicles_df[vehicles_list].join(spark_plants_df[\"plant_id\",\"plant_name\",\"country\",\"iso_country_code\"],spark_vehicles_df['prod_plant_id'] == spark_plants_df['plant_id'],\"left\" ).drop('prod_plant_id','brand','production_country')\n",
        "\n",
        "# #  #Joining vehicle table to orders table\n",
        "vehicle_plant_order_df = spark_vehicles_df.join(spark_orders_df,vehicle_plant_df['order_number']==spark_orders_df['order_number'],\"left\" ).drop('order_number',spark_orders_df['iso_country_code'])\n",
        "\n",
        "# #  #Joining orders table to welcome_call table\n",
        "vehicle_order_reviews = spark_welcome_call_df[\"review_id\",\"vin\",\"order_number\",\"review\",\"ratings\"].join(spark_orders_df,spark_welcome_call_df['order_number']==spark_orders_df['order_number'],\"left\")\n",
        "\n",
        "\n",
        "# Joining the Order_Reviews Dataset to the customers dataset, \n",
        "# this JOIN will help us understand more on the the age groups (and/or other demographics)\n",
        "# of the customers who have conducted reviews as per welcome\n",
        "# It will also help us track the review media that customers in certain geographic areas use\n",
        "vehicle_order_reviews_customer = spark_customers_df_filtered.join(vehicle_order_reviews,spark_customers_df_filtered['customer_id']==vehicle_order_reviews['customer_id'],\"full\").drop('iso_country_code')\n",
        "\n",
        "\n",
        "\n",
        "# # # ##Joining SalesRep data to dealership data,\n",
        "#  this table allows us to map each valid customer addressin order to determine\n",
        "sales_rep_dealership = spark_sales_df_filtered[\"sales_number\",\"first_name\",\"last_name\",\"personnel_number\",\"employment_type\",\"department_code\",\"dealer_number\",\"sex\",\"date_of_birth\",\"customer_address\"].join(spark_dealers_df_filtered[\"dealer_code\",\"dealer_company\",\"dealer_address\"],spark_sales_df_filtered['dealer_number']==spark_dealers_df_filtered['dealer_code'],\"inner\").drop('dealer_code')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XXOXAl0kX7y"
      },
      "source": [
        "#### Question: Did you perform any joins on the datasets. If yes, what joins. Also what information was available after the joins were performed.\n",
        "\n",
        "#### I used left joins as they were the most efficient JOINs that I could use, there is one OUTER join that I used as I wanted to extract some data from the right side table (of course without doing a RIGHT join)\n",
        "\n",
        "# Joined Vehicle Dataframe with Plant Dataframe in order to map the Production Plant ID to a country and also to understand a plant's vehicle production patterns\n",
        "\n",
        "# Joined Vehicle Dataframe with Orders Dataframe in order to get a Vehicle's Order status, CustomerID in order\n",
        "\n",
        "# Joined Welcome Call Dataframe with Dealership Dataframe in order to get more info on customer sentiment at dealerships \n",
        "\n",
        "# The JOINS that were used were all LEFT JOINS, with the bigger table on the left side of the JOINS (in case Spark's Cost Based Optimization does not kick in as it should)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aDRWfnJl_fZ"
      },
      "source": [
        "### Perform All the standard Exploratory Data Analysis in the sections that follow to provide information to the Business users about the data. Report your findings in the form of Graphs or Response statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E-tNWhomPXn"
      },
      "outputs": [],
      "source": [
        "# #####                   #######\n",
        "# ##     Vehicle/Plant Distribution            ##\n",
        "# #####                   #######\n",
        "\n",
        "# # Example: Write down the distribution of Vehicles by plant and iso_country and plot a bar graph\n",
        "\n",
        "vehicle_plant_df.createOrReplaceTempView(\"vehicle_by_plant_dist\")\n",
        "vehicle_by_plant_dist = spark.sql(\"SELECT plant_id, iso_country_code, count(vin) cars_sold FROM vehicle_by_plant_dist group by 1,2 order by 1,2\") #VIN distrbution by plant_id and iso_country_code\n",
        "\n",
        "pandas_vehicle_by_plant_dist = vehicle_by_plant_dist.toPandas()\n",
        "\n",
        "plt.bar(pandas_vehicle_by_plant_dist['iso_country_code'], pandas_vehicle_by_plant_dist['cars_sold'], color='skyblue')\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.xlabel('Country Code')\n",
        "plt.ylabel('Cars Sold')\n",
        "plt.title('Average Price of Vehicles per Plant (in USD)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# #####                   #######\n",
        "# # \n",
        "# # Price per plant and make\n",
        "# # \n",
        "# #####                   #######\n",
        "\n",
        "\n",
        "vehicle_plant_order_df.createOrReplaceTempView(\"vehicle_plant_order_temp_view\")\n",
        "\n",
        "sql_statement_price_per_car = \"\"\"\n",
        "SELECT\n",
        "       production_country,\n",
        "       make,\n",
        "       AVG(price) AS avg_price\n",
        "   FROM\n",
        "       vehicle_plant_order_temp_view\n",
        "   GROUP BY\n",
        "       production_country, make\n",
        "   ORDER BY\n",
        "       avg_price DESC;\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "vehicle_plant_order_temp_view = spark.sql(sql_statement_price_per_car)\n",
        "vehicle_plant_order_pandas_df = vehicle_plant_order_temp_view.toPandas()\n",
        "\n",
        "\n",
        "#  # Price Per Vehicle per Country\n",
        "\n",
        "plt.bar(vehicle_plant_order_pandas_df['production_country'], vehicle_plant_order_pandas_df['avg_price'], color='skyblue')\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.xlabel('Country Code')\n",
        "plt.ylabel('Average Price per Car')\n",
        "plt.title('Average Price of Vehicles per Plant (in USD)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "## Average price per Car Make\n",
        "make_sold_per_country = spark.sql(\"SELECT avg(price) average_make_price , make FROM vehicle_plant_order_temp_view group by make\")\n",
        "make_sold_per_country_pandas = make_sold_per_country.toPandas()\n",
        "plt.bar(make_sold_per_country_pandas['make'], make_sold_per_country_pandas['average_make_price'], color='black')\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.xlabel('Make')\n",
        "plt.ylabel('Average Price per Car Make')\n",
        "plt.title('Average Price of Car Make (in USD)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "vehicle_order_reviews_customer.createOrReplaceTempView(\"vehicle_order_reviews_customer_tempView\")\n",
        "customer_age_group_sentiment_df = spark.sql(\"\"\"\n",
        " SELECT\n",
        "                                        \n",
        "       AVG(ratings) AS avg_rating,\n",
        "       CASE\n",
        "           WHEN AVG(DATEDIFF(CURDATE(), date_of_birth)/365) < 30 THEN 'Under 30'\n",
        "           WHEN AVG(DATEDIFF(CURDATE(), date_of_birth)/365) BETWEEN 30 AND 50 THEN '30-50'\n",
        "           ELSE 'Over 50'\n",
        "       END AS age_group,\n",
        "       date_of_birth\n",
        "   FROM\n",
        "       vehicle_order_reviews_customer_tempView\n",
        "    GROUP BY \n",
        "        ratings, date_of_birth                                                                                           \n",
        "   ORDER BY\n",
        "       avg_rating DESC;\n",
        "\"\"\")\n",
        "customer_age_group_sentiment_pandas_df = customer_age_group_sentiment_df.toPandas()\n",
        "plt.bar(customer_age_group_sentiment_pandas_df['age_group'], customer_age_group_sentiment_pandas_df['avg_rating'], color='skyblue')\n",
        "plt.figure(figsize=(8, 10))\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Rating Average')\n",
        "plt.title('Age Group Ratings')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vehicle_order_reviews_customer.createOrReplaceTempView(\"vehicle_order_reviews_customer_tempView\")\n",
        "customer_age_group_sentiment_df = spark.sql(\"\"\"\n",
        " SELECT\n",
        "                                        \n",
        "       AVG(ratings) AS avg_rating,\n",
        "       CASE\n",
        "           WHEN AVG(DATEDIFF(CURDATE(), date_of_birth)/365) < 30 THEN 'Under 30'\n",
        "           WHEN AVG(DATEDIFF(CURDATE(), date_of_birth)/365) BETWEEN 30 AND 50 THEN '30-50'\n",
        "           ELSE 'Over 50'\n",
        "       END AS age_group,\n",
        "       date_of_birth\n",
        "   FROM\n",
        "       vehicle_order_reviews_customer_tempView\n",
        "    GROUP BY \n",
        "        ratings, date_of_birth                                                                                           \n",
        "   ORDER BY\n",
        "       avg_rating DESC;\n",
        "\"\"\")\n",
        "customer_age_group_sentiment_pandas_df = customer_age_group_sentiment_df.toPandas()\n",
        "plt.bar(customer_age_group_sentiment_pandas_df['age_group'], customer_age_group_sentiment_pandas_df['avg_rating'], color='skyblue')\n",
        "plt.figure(figsize=(8, 10))\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Rating Average')\n",
        "plt.title('Age Group Ratings')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdFMhJHUmZXf"
      },
      "outputs": [],
      "source": [
        "# Write your own exploratory data analysis on the ingested dataframe and report on the different findings. also provide visual aids for each finding.\n",
        "# 1 The Average price of Vehicles in the UK is much higher than the rest of the other plant producers. This is most likely due to all prices being captured in US Dollars and the Euor being stronger \n",
        "# 2 The Rolls Royce also makes up the greatest portion of the pricing that is in England\n",
        "# 3 The sentiment reviews for the most part are quite consistent across age groups\n",
        "# 4 \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhk3rwcsmt3H"
      },
      "source": [
        "### Report all your Findings:\n",
        "\n",
        "Report your findings in bullet points.\n",
        "Example: For illustration purpose only - replace below with your own findings and support with Evidence\n",
        "1. The US plant manufactured the most number of vehicles in 2023 etc. There were 30,000 vehicles manufactured at the plant etc.\n",
        "2. Prices in the UK were "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb1_0AKGmlO0"
      },
      "source": [
        "## `Acceptance Criteria`\n",
        "The following acceptance criteria must be met:\n",
        "\n",
        "1. Perform Exploratory data Analysis and present your results as observations.\n",
        "2. Python Graph libraries must be used to plot graphs to support your findings.\n",
        "3. Comment your notebook file with markdown indicating observations: and write statements to indicate your observations.\n",
        "4. Perform Analysis fo the Data using Spark or Pandas"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
